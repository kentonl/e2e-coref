# Word embeddings.
glove_300d {
  path = glove.840B.300d.txt
  size = 300
  format = txt
  lowercase = false
}
glove_300d_filtered {
  path = glove.840B.300d.txt.filtered
  size = 300
  format = txt
  lowercase = false
}
turian_50d {
  path = turian.50d.txt
  size = 50
  format = txt
  lowercase = false
}
word2vec_300d {
  path = word2vec.300d.txt
  size = 300
  format = vec
  lowercase = false
}

word2vec_300d_filtered {
  path = word2vec.300d.txt.filtered
  size = 300
  format = txt
  lowercase = false
}

# Compute clusters.
nlp {
  addresses {
    ps = [nlp2:2222]
    worker = [n01:2222, n02:2222, n03:2222, n04:2222, n05:2222, n07:2222, n08:2222, n09:2222, n10:2222, n11:2222, n12:2222, n13:2222, n14:2222, n15:2222, n16:2222]
  }
  gpus = [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
}
appositive {
  addresses {
    ps = [localhost:2222]
    worker = [localhost:2223, localhost:2224]
  }
  gpus = [0, 1]
}

# Main configuration.
best {
  # Computation limits.
  max_antecedents = 250
  max_training_sentences = 50
  mention_ratio = 0.4

  # Model hyperparameters.
  filter_widths = [3, 4, 5]
  filter_size = 50
  char_embedding_size = 8
  char_vocab_path = "char_vocab.chinese.txt"
  embeddings = [${glove_300d_filtered}, ${turian_50d}]
  lstm_size = 200
  ffnn_size = 150
  ffnn_depth = 2
  feature_size = 20
  max_mention_width = 10
  use_metadata = true
  use_features = true
  model_heads = true

  # Learning hyperparameters.
  max_gradient_norm = 5.0
  lexical_dropout_rate = 0.5
  dropout_rate = 0.2
  optimizer = adam
  learning_rate = 0.001
  decay_rate = 0.999
  decay_frequency = 100

  # Other.
  train_path = train.chinese.jsonlines
  eval_path = dev.chinese.jsonlines
  conll_eval_path = dev.chinese.v4_auto_conll
  genres = [bc, bn, mz, nw, pt, tc, wb]
  eval_frequency = 1000
  report_frequency = 100
  log_root = logs
  cluster = ${appositive}
}

# Multiple full models for ensembling.
best0 = ${best}
best1 = ${best}
best2 = ${best}
best3 = ${best}
best4 = ${best}

# Ablations.
glove = ${best} {
  embeddings = [${glove_300d_filtered}]
}
turian = ${best} {
  embeddings = [${turian_50d}]
}
nochar = ${best} {
  char_embedding_size = -1
}
nometa = ${best} {
  use_metadata = false
}
noheads = ${best} {
  model_heads = false
}
nofeatures = ${best} {
  use_features = false
}
word2vec = ${best} {
  embeddings = [${word2vec_300d_filtered}]
}

# For evaluation. Do not use for training (i.e. only for decoder.py, ensembler.py, visualize.py and demo.py). Rename `best0` directory to `final`.
final = ${best} {
  embeddings = [${glove_300d}, ${turian_50d}]
  eval_path = test.english.jsonlines
  conll_eval_path = test.english.v4_gold_conll
}

best_en = ${best} {
  embeddings = [${glove_300d}, ${turian_50d}]
  eval_path = test.english.jsonlines
  conll_eval_path = test.english.v4_gold_conll
}

# glove_300d_filtered
final_chinese = ${best} {
  embeddings = [${word2vec_300d}]
  eval_path = test.chinese.jsonlines
  conll_eval_path = test.chinese.v4_gold_conll
}